{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Vjanac6NPR4Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 14:51:32.438223: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-13 14:51:32.438242: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import requests\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# load wikidata API\n",
    "url = 'https://www.wikidata.org/w/api.php'\n",
    "# a header to get access to more requests\n",
    "headers = {'User-Agent': 'NicBot/0.0 (N.c.brand@student.rug.nl)'}\n",
    "\n",
    "# json parameters for entities\n",
    "entParams = {'action':'wbsearchentities', \n",
    "          'language':'en',\n",
    "          'limit':'2',\n",
    "          'format':'json'}\n",
    "\n",
    "# json parameters for properties\n",
    "propParams = {'action':'wbsearchentities', \n",
    "          'type':'property',\n",
    "          'language':'en',\n",
    "          'limit':'5',\n",
    "          'format':'json'}\n",
    "\n",
    "# map languages\n",
    "lang_upper = {'German': 'de',\n",
    "        'English': 'en',\n",
    "        'French': 'fr',\n",
    "        'Dutch': 'nl',\n",
    "        'Japanese': 'ja',\n",
    "        'Chinese': 'zh',\n",
    "        'Spanish': 'es',\n",
    "        'Arabic': 'ar',\n",
    "        'Hindi': 'hi',\n",
    "        'Portugese': 'pt',\n",
    "        'Italian': 'it',\n",
    "        'Russian': 'ru'\n",
    "       }\n",
    "\n",
    "lang_lower = {'german': 'de',\n",
    "        'english': 'en',\n",
    "        'french': 'fr',\n",
    "        'dutch': 'nl',\n",
    "        'japanese': 'ja',\n",
    "        'chinese': 'zh',\n",
    "        'spanish': 'es',\n",
    "        'arabic': 'ar',\n",
    "        'hindi': 'hi',\n",
    "        'portugese': 'pt',\n",
    "        'italian': 'it',\n",
    "        'russian': 'ru'\n",
    "       }\n",
    "\n",
    "# map common synonyms to correct properties\n",
    "rules = {'name': 'rdfs:label',\n",
    "         'scientific': 'P225',\n",
    "         'pregnant': 'P3063',\n",
    "         'weigh': 'P2067',\n",
    "         #'eat': 'P1034',\n",
    "         'tall': 'P2048',\n",
    "         'old': 'P4214',\n",
    "         'make': 'P1672',\n",
    "         'come': 'P183',\n",
    "         'extinct': 'P582',\n",
    "         'study': 'P2579',\n",
    "         #'consist': 'P527',\n",
    "         'component':'P527',\n",
    "         'endemic':'P183',\n",
    "         'edible': 'Q9323487',\n",
    "         'fur': 'P462'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "KUBMFxfGQV_N"
   },
   "outputs": [],
   "source": [
    "#Visualization \n",
    "# displacy.render(parse, jupyter=True, style=\"ent\")\n",
    "\n",
    "# displacy.render(parse, jupyter=True, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YBAkLZxb1bXb"
   },
   "outputs": [],
   "source": [
    "# Helper function to iterate through the rules, no matter the type\n",
    "def checkRules(lemma, rules, outputList):\n",
    "    if lemma in rules:\n",
    "        if type(rules.get(lemma)) is list:\n",
    "            for item in rules.get(lemma):\n",
    "                outputList.append(item)\n",
    "        else:\n",
    "            outputList.append(rules.get(lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vC9j_UWrBQQM"
   },
   "outputs": [],
   "source": [
    "# Maria's code\n",
    " \n",
    "\n",
    "# # If there is a 'too many requests error' its probably in these 2 functions\n",
    "def getLabel(query): \n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    \n",
    "    try:\n",
    "        results = requests.get(url, params={'query': query, 'format': 'json'}).json()\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "    for item in results['results']['bindings']:\n",
    "        for var in item:\n",
    "            print('{}\\t{}'.format(var,item[var]['value']))\n",
    "\n",
    "\n",
    "def getResults(query, label_query):\n",
    "    \n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    \n",
    "    try:\n",
    "        results = requests.get(url, params={'query': query, 'format': 'json'}).json()\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "    for item in results['results']['bindings']:\n",
    "        for var in item:\n",
    "            print('{}\\t{}'.format(var,item[var]['value']))\n",
    "            if type(item[var]['value']) == str:\n",
    "                getLabel(label_query)\n",
    "        return item[var]['value']\n",
    "    return 'null'\n",
    "\n",
    "def checkCompound(parse, token):\n",
    "    for i, word in enumerate(parse): \n",
    "        if word.dep_ == \"compound\" and str(parse[i+1]) == token.text:\n",
    "            compound = word\n",
    "            return compound\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def checkAmod(parse, token):\n",
    "    for i, word in enumerate(parse):\n",
    "        if word.dep_ == \"amod\" and str(parse[i+1]) == token.text:\n",
    "            amod = word\n",
    "            return amod\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def checkAcomp(parse, token):\n",
    "    for i, word in enumerate(parse):\n",
    "        if word.dep_ == \"acomp\" and str(parse[i+1]) == token.text:\n",
    "            if word.text == \"strong\":\n",
    "                acomp = \"force quotient\"\n",
    "                return acomp\n",
    "    return 0\n",
    "\n",
    "\n",
    "def checkEntityAdj(parse, token_text):\n",
    "    for i, word in enumerate(parse):\n",
    "        if word.pos_ == \"ADJ\" and i != len(parse)-1:\n",
    "            if parse[i+1] == token_text:\n",
    "                entAdj = word\n",
    "                return entAdj\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def getID(token):\n",
    "    params = {'action':'wbsearchentities', \n",
    "           'language':'en',\n",
    "           'format':'json'}\n",
    "    print(token.text)\n",
    "    compound = checkCompound(parse, token)\n",
    "    if token.dep_ != \"amod\":\n",
    "        amod = checkAmod(parse, token)\n",
    "    else:\n",
    "        amod = 0\n",
    "    \n",
    "    entAdj = checkEntityAdj(parse, token)\n",
    "\n",
    "    if type(compound) != int :\n",
    "        text = compound.text + ' ' + token.text\n",
    "    elif type(amod) != int:\n",
    "        text = amod.text + ' ' + token.text\n",
    "    \n",
    "    elif type(entAdj) != int:\n",
    "        text = entAdj.text + ' ' + token.text\n",
    "    else:\n",
    "        text = token.text\n",
    "        \n",
    "    params['search'] = text\n",
    "    try:\n",
    "        json = requests.get(url,params).json()\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    # If its not initialized then initialize ID here as 0 or something and then check if its an int \n",
    "    for result in json['search']:\n",
    "        if result['label'] == text:\n",
    "            ID = result['id']\n",
    "            return ID\n",
    "        elif text in result['label']:\n",
    "            ID = result['id']\n",
    "            return ID    \n",
    "    return \n",
    "\n",
    "# # Similarly to the getID() function, this one returns the ID of the property\n",
    "def getID_property(token):\n",
    "    params = {'action':'wbsearchentities', \n",
    "              'type':'property',\n",
    "              'language':'en',\n",
    "              'format':'json'}\n",
    "    print(token.text)\n",
    "    compound = checkCompound(parse, token)\n",
    "    acomp = checkAcomp(parse, token)\n",
    "    \n",
    "    if type(compound) != int :\n",
    "        text = compound.text + ' ' + token.text\n",
    "    elif type(acomp) != int :\n",
    "        text = token.text + ' ' + acomp\n",
    "    else:\n",
    "        text = token.text\n",
    "\n",
    "    params['search'] = text\n",
    "    \n",
    "    json = requests.get(url,params).json()\n",
    "\n",
    "    # If its not initialized then initialize ID here as 0 or something and then check if its an int \n",
    "    for result in json['search']:\n",
    "        \n",
    "        if result['label'] == text:\n",
    "            ID = result['id']\n",
    "            return ID\n",
    "\n",
    "        elif text in result['label']:\n",
    "            ID = result['id']\n",
    "            return ID\n",
    "\n",
    "  \n",
    "    return \n",
    "\n",
    "def getID_property_str(token_text): # The same as getID_property, but it takes string instead of token as an argument\n",
    "    params = {'action':'wbsearchentities', \n",
    "              'type':'property',\n",
    "              'language':'en',\n",
    "              'format':'json'}\n",
    "    \n",
    "\n",
    "    text = token_text\n",
    "    \n",
    "\n",
    "    params['search'] = text\n",
    "    \n",
    "    json = requests.get(url,params).json()\n",
    "    # If its not initialized then initialize ID here as 0 or something and then check if its an int \n",
    "    for result in json['search']:\n",
    "        \n",
    "        if result['label'] == text:\n",
    "            ID = result['id']\n",
    "            return ID\n",
    "            break\n",
    "        elif text in result['label']:\n",
    "            ID = result['id']\n",
    "            return ID\n",
    "            break\n",
    "  \n",
    "    return \n",
    "\n",
    "def tryAgain(question):\n",
    "    ID1_token = ''\n",
    "    ID2_token = ''\n",
    "    ID2_token_text = 0   \n",
    "    # Parsing the question and printing values to check - \n",
    "    # since I solved the previous assignment with dependencies, \n",
    "    # the code worked for both \"What\" and \"How\" questions, thus \n",
    "    # I extended the program with \"Where\" and \"When\" questions\n",
    "\n",
    "    # Where and When questions are pretty specific in terms of \n",
    "    # plants and animals thus I added some extra conditions\n",
    "\n",
    "    if str(parse[0]) == \"Where\": # Finding the token of the property and the entity for Where questions\n",
    "        ID2_token_text = \"endemic to\"\n",
    "        for word in parse:\n",
    "            if word.dep_ == \"nsubj\" and word.text != 'you':\n",
    "                ID1_token = word  \n",
    "            elif word.dep_ == \"dobj\":\n",
    "                ID1_token = word\n",
    "\n",
    "    if str(parse[0]) == \"When\": # Finding the token of the property and the entity for When questions\n",
    "\n",
    "        for word in parse:\n",
    "            if word.dep_ == \"nsubj\":\n",
    "                ID1_token = word  \n",
    "            if word.dep_ == \"acomp\":\n",
    "                if word.text == 'extinct':\n",
    "                    ID2_token_text = 'extinction date'\n",
    "                elif word.text == \"alive\" or word.text == \"living\":\n",
    "                    ID2_token_text = 'start time'\n",
    "\n",
    "    elif str(parse[0]) == \"How\" or str(parse[0]) == \"What\":\n",
    "        for word in parse : # iterate over the token objects \n",
    "            print(word.text, word.lemma_, word.pos_, word.dep_)\n",
    "\n",
    "            if word.dep_ == \"nsubj\" :\n",
    "                ID2_token = word    # Finding the token of the property for What and How questions\n",
    "\n",
    "            if word.dep_ == \"pobj\":\n",
    "                ID1_token =  word   # Finding the token of the entity for What and How questions\n",
    "\n",
    "\n",
    "    for ent in parse.ents : \n",
    "        print(ent.text, ent.label_)\n",
    "    \n",
    "    if ID1_token and ID2_token:\n",
    "        ID1 = getID(ID1_token)\n",
    "        if type(ID2_token_text) != int:\n",
    "            ID2 = getID_property_str(ID2_token_text)\n",
    "        else:\n",
    "            ID2 = getID_property(ID2_token)\n",
    "\n",
    "        if ID1 is None or ID2 is None:\n",
    "            return \n",
    "    else:\n",
    "        return\n",
    "    query = 'SELECT ?answer WHERE { wd:' + ID1 + ' wdt:' + ID2 + ' ?answer}'\n",
    "\n",
    "    # If the answer is an URL, this query will serve to also print the label \n",
    "    label_query = 'SELECT ?answerLabel WHERE { wd:' + ID1 + ' wdt:' + ID2 + ' ?answer. ?answer rdfs:label ?answerLabel. FILTER(lang(?answerLabel)=\"en\")}LIMIT 1'\n",
    "\n",
    "    print(question)\n",
    "    return getResults(query, label_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmtxTu1t8-1q",
    "outputId": "e78e0bfc-de95-4db3-f85d-bab236d1f764"
   },
   "outputs": [],
   "source": [
    "# Bianca's code:\n",
    "\n",
    "def getAnswer(question):\n",
    "\n",
    "    # arrays/lists to save all found IDs/URIs of entities and properties\n",
    "    ents = []\n",
    "    props = []\n",
    "\n",
    "    langFilter = ''\n",
    "    addition = ''\n",
    "    rootFlag = False\n",
    "    ofOrFromInSentence = False\n",
    "    objInSentence = False\n",
    "    yesNoQuestion = False\n",
    "    countQuestion = False\n",
    "    noSubject = True\n",
    "    flip_answer = False \n",
    "    languageFound = ''\n",
    "\n",
    "    # parse the question \n",
    "    parse = nlp(question) \n",
    "\n",
    "    # use entities to detect languages - what about e.g., \"German Shepard\"?\n",
    "    for ent in parse.ents:\n",
    "        if ent.label_ == 'NORP':\n",
    "            languageFound = ent\n",
    "            print('language found: ' + ent.lemma_)\n",
    "            print(ent.lemma_)\n",
    "            if ent.lemma_ in lang_lower.keys():\n",
    "                langFilter = 'FILTER (lang(?answer) = \"' + str(lang_lower.get(ent.lemma_)) + '\")'\n",
    "            elif ent.lemma_ in lang_upper.keys():\n",
    "                langFilter = 'FILTER (lang(?answer) = \"' + str(lang_upper.get(ent.lemma_)) + '\")'\n",
    "            print(langFilter)\n",
    "\n",
    "\n",
    "    # parse once to check question structure - add question qualification (what, where, who etc.) here\n",
    "    for word in parse:\n",
    "        print(word.text, word.lemma_, word.pos_, word.dep_)\n",
    "        if word.text == str(languageFound) and parse[word.i + 1].text.istitle():\n",
    "            langFilter = ''\n",
    "            languageFound = ''\n",
    "        # if the question contains 'of' or 'from' and they are not the last word in the question\n",
    "        if (word.text == 'of' or word.text == 'from') and word.text != parse[-2].text:\n",
    "            ofOrFromInSentence = True\n",
    "        if 'different from' in question:\n",
    "            flip_answer = True   \n",
    "        if word.dep_ == 'nsubj' or word.dep_ == 'nsubjpass':\n",
    "            noSubject = False\n",
    "        # if the question contains an object\n",
    "        if word.dep_ == 'pobj' or word.dep_ == 'dobj' or word.dep_ == 'attr' or word.dep_ == 'acomp':\n",
    "            objInSentence = True\n",
    "        # if the question is a count question\n",
    "        if word.text == 'many':\n",
    "            countQuestion = True\n",
    "    # parse once again to check question structure, this is needed due to the possibility of having an object at the last position\n",
    "    for word in parse:\n",
    "        if parse[0].pos_ == 'VERB' or parse[0].pos_ == 'AUX':\n",
    "            rootFlag = False\n",
    "            yesNoQuestion = True\n",
    "            break\n",
    "        # if the voice is passive, the property has to be an nsubj or nsubjpass\n",
    "        if word.dep_ == 'auxpass':\n",
    "            rootFlag = False\n",
    "            break\n",
    "        # if the verb is the ROOT or could be the case that the question contains modal verbs, e.g. \n",
    "        # 'Which colour can foxes be?', then the entity has to be an nsubj'\n",
    "        if word.pos_ == 'VERB' or (word.pos_ == 'AUX' and word.text == parse[-2].text):\n",
    "            if word.dep_ == 'ROOT':\n",
    "                rootFlag = True\n",
    "            else:\n",
    "                if not ofOrFromInSentence:\n",
    "                    rootFlag = True       \n",
    "\n",
    "    # for 'endemic to' examples and other ones\n",
    "    if not yesNoQuestion and not rootFlag and not objInSentence:\n",
    "        rootFlag = True          \n",
    "\n",
    "    # iterate through parsed words\n",
    "    for word in parse:\n",
    "        # check for specific rules, synonyms etc\n",
    "        if not yesNoQuestion:\n",
    "            checkRules(word.lemma_, rules, props)\n",
    "        else:\n",
    "            if not str(rules.get(word.lemma_)).startswith('P'):\n",
    "                ents.append(rules.get(word.lemma_))\n",
    "\n",
    "        # iterate through word positions\n",
    "        if word.pos_:\n",
    "            # if adjective or adverb, extend words for websearch\n",
    "            if word.pos_ == 'ADJ' or word.pos_ == 'ADV':\n",
    "                if word.dep_ == 'amod' or word.dep_ == 'compound' or word.dep_ == 'advmod':\n",
    "                    addition = addition + ' ' + word.text\n",
    "\n",
    "            # if noun, search for URI (entity), searches for whole words only at this point - needs adjustments for spans\n",
    "            if word.pos_ == 'NOUN' or word.pos_ == 'PROPN' or word.pos_ == 'NUM' or word.pos_ == 'VERB' or word.pos_ == 'ADJ':\n",
    "                if word.dep_ == 'compound':\n",
    "                    # maybe not necessary\n",
    "                    if word.pos_ == 'NOUN' or word.pos_ == 'PROPN':\n",
    "                         addition = addition + ' ' + word.lemma_\n",
    "                    else: \n",
    "                        addition = addition + ' ' + word.text\n",
    "\n",
    "                if not rootFlag:\n",
    "                    # if pobj, an entity has been found\n",
    "                    if word.dep_ == 'pobj' or word.dep_ == 'dobj' or word.dep_ == 'attr' or word.dep_ == 'acomp':\n",
    "                        # for 'endemic to'\n",
    "                        if word.lemma_ in rules and addition:\n",
    "                            entParams['search'] = addition\n",
    "                        else:\n",
    "                            entParams['search'] = addition + ' ' + word.lemma_\n",
    "                        json = requests.get(url,entParams, headers=headers).json()\n",
    "                        for result in json['search']:\n",
    "                            if 'description' in result:\n",
    "                                # save all IDs of interest for entities\n",
    "                                ents.append(result['id'])\n",
    "                        # if nothing could be found with the extension, try shortened version\n",
    "                        addition = ''\n",
    "                        if not ents:\n",
    "                            entParams['search'] = addition + ' ' + word.lemma_\n",
    "                            json = requests.get(url,entParams, headers=headers).json()\n",
    "                            for result in json['search']:\n",
    "                                if 'description' in result:\n",
    "                                    # save all IDs of interest for entities\n",
    "                                    ents.append(result['id'])\n",
    "                                    \n",
    "                    # if nsubj, a property has been found\n",
    "                    elif (word.dep_ == 'nsubj' or word.dep_ == 'nsubjpass' or word.dep_ == 'pcomp' or word.dep_ == 'ROOT' or word.dep_ == 'nmod') and word.pos_ != 'VERB':\n",
    "                        if yesNoQuestion:\n",
    "                            entParams['search'] = addition + ' ' + word.lemma_\n",
    "                            json = requests.get(url,entParams, headers=headers).json()\n",
    "                        else:\n",
    "                            propParams['search'] = addition + ' ' + word.lemma_\n",
    "                            json = requests.get(url,propParams, headers=headers).json()\n",
    "                        for result in json['search']:\n",
    "                            if 'description' in result:\n",
    "                                # save all IDs of interest for properties\n",
    "                                props.append(result['id'])\n",
    "                        # added for average litter size example and other ones\n",
    "                        if addition.rfind(' ') != 0:\n",
    "                            addition = addition.split(\" \", 2)[-1]\n",
    "                        else:\n",
    "                            addition = ''\n",
    "                        # if nothing could be found with the extension, try shortened version\n",
    "                        if not props or (yesNoQuestion and not objInSentence):\n",
    "                            if yesNoQuestion:\n",
    "                                entParams['search'] = addition + ' ' + word.lemma_\n",
    "                                json = requests.get(url,entParams, headers=headers).json()\n",
    "                            else:\n",
    "                                propParams['search'] = addition + ' ' + word.lemma_\n",
    "                                json = requests.get(url,propParams, headers=headers).json()\n",
    "                            for result in json['search']:\n",
    "                                if 'description' in result:\n",
    "                                    # save all IDs of interest for properties\n",
    "                                    if yesNoQuestion:\n",
    "                                        ents.append(result['id'])\n",
    "                                    else:\n",
    "                                        props.append(result['id'])\n",
    "                 # new addition\n",
    "                    elif yesNoQuestion and not objInSentence and addition:\n",
    "                        entParams['search'] = addition\n",
    "                        json = requests.get(url,entParams, headers=headers).json()\n",
    "                        for result in json['search']:\n",
    "                            if 'description' in result:\n",
    "                                # save all IDs of interest for properties\n",
    "                                props.append(result['id'])\n",
    "\n",
    "                    elif yesNoQuestion and noSubject and addition:\n",
    "                        entParams['search'] = addition\n",
    "                        json = requests.get(url,entParams, headers=headers).json()\n",
    "                        for result in json['search']:\n",
    "                            if 'description' in result:\n",
    "                                # save all IDs of interest for properties\n",
    "                                props.append(result['id'])\n",
    "\n",
    "                # a ROOT verb is there, the syntax changes\n",
    "                else:\n",
    "                    # if nsubj or nsubjpass, an entity has been found\n",
    "                    if word.dep_ == 'nsubj' or word.dep_ == 'nsubjpass':\n",
    "                        entParams['search'] = addition + ' ' + word.lemma_\n",
    "                        json = requests.get(url,entParams, headers=headers).json()\n",
    "                        for result in json['search']:\n",
    "                            if 'description' in result:\n",
    "                                # save all IDs of interest for entities\n",
    "                                ents.append(result['id'])\n",
    "                        # if nothing could be found with the extension, try shortened version\n",
    "                        if not ents:\n",
    "                            if addition.istitle(): # added for Old Tjikko tree and other examples \n",
    "                                entParams['search'] = addition\n",
    "                            else:\n",
    "                                addition = ''\n",
    "                                entParams['search'] = addition + ' ' + word.lemma_\n",
    "                            json = requests.get(url,entParams, headers=headers).json()\n",
    "                            for result in json['search']:\n",
    "                                if 'description' in result:\n",
    "                                    # save all IDs of interest for entities\n",
    "                                    ents.append(result['id'])\n",
    "\n",
    "                    if word.dep_ == 'pobj' or word.dep_ == 'dobj' or word.dep_ == 'attr' or word.dep_ == 'pcomp':\n",
    "                        propParams['search'] = addition + ' ' + word.lemma_\n",
    "                        json = requests.get(url,propParams, headers=headers).json()\n",
    "                        for result in json['search']:\n",
    "                            if 'description' in result:\n",
    "                                # save all IDs of interest for properties\n",
    "                                props.append(result['id'])\n",
    "                        # I do not remember exactly for what examples was needed\n",
    "                        if addition.rfind(' ') != 0:\n",
    "                            addition = addition.split(' ', 2)[-1]\n",
    "                        else:\n",
    "                            addition = ''\n",
    "                        # if nothing could be found with the extension, try shortened version\n",
    "                        if not props:\n",
    "                            propParams['search'] = addition + ' ' + word.lemma_\n",
    "                            json = requests.get(url,propParams, headers=headers).json()\n",
    "                            for result in json['search']:\n",
    "                                if 'description' in result:\n",
    "                                    # save all IDs of interest for properties\n",
    "                                    props.append(result['id'])\n",
    "                                    \n",
    "                if not yesNoQuestion and word.pos_ == 'VERB':\n",
    "                    # check for potential properties associated with the word - usually uses rules, though\n",
    "                    if word.dep_ == 'ROOT':\n",
    "                        propParams['search'] = addition + ' ' + word.lemma_\n",
    "                        json = requests.get(url,propParams, headers=headers).json()\n",
    "                        for result in json['search']:\n",
    "                            if 'description' in result:\n",
    "                                # save all IDs of interest for properties\n",
    "                                props.append(result['id'])\n",
    "                        addition = ''\n",
    "                        # if nothing could be found with the extension, try shortened version\n",
    "                        if not props:\n",
    "                            propParams['search'] = word.lemma_\n",
    "                            json = requests.get(url,propParams, headers=headers).json()\n",
    "                            for result in json['search']:\n",
    "                                if 'description' in result:\n",
    "                                    # save all IDs of interest for properties n \n",
    "                                    props.append(result['id'])\n",
    "    \n",
    "    filtered_ents = list(filter(None, ents))\n",
    "    filtered_props = list(filter(None, props))\n",
    "    # maybe not necessary\n",
    "    if yesNoQuestion:\n",
    "        \n",
    "        filtered_ents, filtered_props = filtered_props, filtered_ents\n",
    "        \n",
    "    print('found entitites: ', filtered_ents)\n",
    "    print('found properties ', filtered_props)\n",
    "\n",
    "    # load query url\n",
    "    queryUrl = 'https://query.wikidata.org/sparql'\n",
    "    # arrays/lists to save all found labels and values of the answer\n",
    "    answers_labels = []\n",
    "    answer_values = []\n",
    "    yes_no_answer = []\n",
    "    \n",
    "    # iterate through entities and construct query\n",
    "    for entIdx in filtered_ents:\n",
    "        # iterate through properties and build the query\n",
    "        for propIdx in filtered_props:\n",
    "            # print('searching for entity ' + str(entIdx) + ' and property ' + str(propIdx))\n",
    "            if not yesNoQuestion and langFilter and not countQuestion:\n",
    "                query = 'SELECT ?answerLabel WHERE { wd:' + entIdx + ' rdfs:label' + ' ?answer.' + langFilter + ' SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . } }'\n",
    "            # new addition\n",
    "            elif yesNoQuestion:\n",
    "                query = 'ASK { wd:' + entIdx + ' wdt:P171*|wdt:P31|wdt:P279*|wdt:P1672|wdt:P141|wdt:P2283|wdt:P1034|wdt:P366|wdt:P462' + ' wd:' + propIdx + ' SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }}'                \n",
    "            elif countQuestion:\n",
    "                # this also covers disguised what questions\n",
    "                query = getCountQuery(parse, entIdx, propIdx, langFilter)\n",
    "            else:\n",
    "                query = 'SELECT ?answerLabel WHERE { wd:' + entIdx + ' wdt:' + propIdx + ' ?answer. SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . } }'\n",
    "            \n",
    "            # for sending too many requests\n",
    "            try:\n",
    "                data = requests.get(queryUrl, params={'query': query, 'format': 'json'}, headers=headers).json()\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            if yesNoQuestion:\n",
    "                yes_no_answer.append(data['boolean'])\n",
    "            else:\n",
    "                for item in data['results']['bindings']:\n",
    "                    for var in item:\n",
    "                        print('{}\\t{}'.format(var, item[var]['value']))\n",
    "                        answers_labels.append(var)\n",
    "                        answer_values.append(item[var]['value'])\n",
    "            # exit the function if an answer has been found as it is usually correct        \n",
    "            if len(answers_labels) != 0 and len(answer_values) != 0:\n",
    "                return \", \".join(answer_values)\n",
    "            elif yesNoQuestion:\n",
    "                if True in yes_no_answer:\n",
    "                    if not flip_answer:\n",
    "                        print(\"yes\")\n",
    "                        return \"yes\"\n",
    "                    else:\n",
    "                        print(\"no\")\n",
    "                        return \"no\"\n",
    "                    return\n",
    "    if yesNoQuestion:\n",
    "        if not flip_answer:\n",
    "            print(\"no\")\n",
    "            return \"no\"\n",
    "        else:\n",
    "            print(\"yes\")\n",
    "            return \"yes\"\n",
    "        return\n",
    "    elif len(answers_labels) == 0 and len(answer_values) == 0:\n",
    "        return tryAgain(question)\n",
    "        #print('No answer could be found')\n",
    "        #return('No answer could be found')\n",
    "        \n",
    "# If it is run with input json file, this needs to be commented out\n",
    "#question = input('Please ask your question\\n')\n",
    "#parse = nlp(question)\n",
    "#getAnswer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7Wr5WyPv8fqk"
   },
   "outputs": [],
   "source": [
    "# Niclas' code\n",
    "# the dependencies shown here differ from the ones in my juypter notebook - I need to adjust this. Shouldn't take long if the property is always 'attr'\n",
    "def getCountQuery(parseQ, entIdx, propIdx, langFilter):\n",
    "    ents = []\n",
    "    props = []\n",
    "    \n",
    "    for word in parseQ:\n",
    "        # check for specific rules, synonyms etc\n",
    "        checkRules(word.lemma_, rules, props\n",
    "                   )\n",
    "        # sort the nsubjs to their respective POS/dependencies\n",
    "        if word.dep_ == 'nsubj':\n",
    "            # if it is the first (and only) nsubj, it should be the entity\n",
    "            if ents:\n",
    "                ents.append(word.lemma_)\n",
    "            # if there is a second nsubj, the first nsubj becomes the entity\n",
    "            # and the entity is replaced by the second nsubj \n",
    "            else:\n",
    "                props.append(ents)\n",
    "                ents.clear()\n",
    "                ents.append(word.lemma_)\n",
    "\n",
    "        # if adjective or adverb, or compund noun extend words for entity websearch\n",
    "        if word.pos_ == 'ADJ' or word.pos_ == 'ADV' or word.pos_ == 'NOUN' or word.pos_ == 'PROPN':\n",
    "            if word.dep_ == 'amod' or word.dep_ == 'compound' or word.dep_ == 'advmod':\n",
    "                addition = addition + ' ' + word.text\n",
    "                \n",
    "        # if only one nsubj, the dobj is the property\n",
    "        if word.dep_ == 'dobj':\n",
    "            # this needs to find the synonyms for properties, \n",
    "            # such as pup(pie)s/eggs as synonyms for litter size\n",
    "            ## if addition:\n",
    "                ## props.append(classifier(addition))\n",
    "            ## else:\n",
    "                ## props.append(classifier(word.lemma_)) \n",
    "            # naive approach for now\n",
    "            props.append(word.lemma_)\n",
    "    \n",
    "    # construct count query with corresponding entity and property indeces\n",
    "    if langFilter:\n",
    "        # try with normal what query first (disguised question)\n",
    "        query = 'SELECT ?answer WHERE { wd:' + entIdx + ' wdt:' + propIdx + ' ?answer.' + langFilter + ' SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . } }'\n",
    "        # If the answer is an URL, this query will serve to also print the label \n",
    "        label_query = 'SELECT ?answerLabel WHERE { wd:' + entIdx + ' wdt:' + propIdx + ' ?answer. ?answer rdfs:label ?answerLabel. FILTER(lang(?answerLabel)=\"en\")}LIMIT 1'\n",
    "        # if this works, return the answer, otherwise do an actual counting operation\n",
    "        if getResults(query, label_query):\n",
    "            return getResults(query, label_query)\n",
    "        else: \n",
    "            return 'SELECT (COUNT(?answer) as ?sum_of_answer) WHERE { wd:' + entIdx + ' wdt:' + propIdx + ' ?answer.' + langFilter + ' SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . } }'\n",
    "\n",
    "    else:\n",
    "        # try with normal what query first (disguised question)\n",
    "        query = 'SELECT ?answer WHERE { wd:' + entIdx + ' wdt:' + propIdx + ' ?answer. SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . } }'\n",
    "        label_query = 'SELECT ?answerLabel WHERE { wd:' + entIdx + ' wdt:' + propIdx + ' ?answer. ?answer rdfs:label ?answerLabel. FILTER(lang(?answerLabel)=\"en\")}LIMIT 1'\n",
    "        if getResults(query, label_query):\n",
    "            return getResults(query, label_query)\n",
    "        else: \n",
    "            return 'SELECT (COUNT(?answer) as ?sum_of_answer) WHERE { wd:' + entIdx + ' wdt:' + propIdx + ' ?answer. SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . } }'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "iW8p0JYu8kyZ",
    "outputId": "b6dfe893-c243-4464-b774-8dc16ecef1b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class '_io.TextIOWrapper'>\n",
      "input_data:  <class 'str'>\n",
      "i:  {'id': 1, 'question': 'What is the colour of milk?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "colour colour NOUN nsubj\n",
      "of of ADP prep\n",
      "milk milk NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q8495', 'Q10988133']\n",
      "found properties  ['P462', 'P1227', 'P1884', 'P465', 'P6338']\n",
      "answerLabel\twhite\n",
      "i:  {'id': 2, 'question': 'What are the parts of a tree?', 'answer': 'trunk, branch, leaf, root', 'correct': 0.5}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "are be AUX ROOT\n",
      "the the DET det\n",
      "parts part NOUN nsubj\n",
      "of of ADP prep\n",
      "a a DET det\n",
      "tree tree NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q10884', 'Q223655']\n",
      "found properties  ['P1107', 'P1433', 'P59', 'P361', 'P179']\n",
      "answerLabel\tforest\n",
      "answerLabel\tphanerophyte\n",
      "i:  {'id': 3, 'question': 'What is the size of an elephant?', 'answer': None, 'correct': 0}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "size size NOUN nsubj\n",
      "of of ADP prep\n",
      "an an DET det\n",
      "elephant elephant NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q7378', 'Q2372824']\n",
      "found properties  ['P2048', 'P2049', 'P2046', 'P2043', 'P2053']\n",
      "answerLabel\t4\n",
      "i:  {'id': 4, 'question': 'Is milk white?', 'answer': 'yes', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "Is be AUX ROOT\n",
      "milk milk NOUN nsubj\n",
      "white white ADJ acomp\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q8495', 'Q10988133']\n",
      "found properties  ['Q23444', 'Q6933946']\n",
      "yes\n",
      "i:  {'id': 5, 'question': 'What do cows eat?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON dobj\n",
      "do do AUX aux\n",
      "cows cow NOUN nsubj\n",
      "eat eat VERB ROOT\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q830', 'Q11748378']\n",
      "found properties  ['P1034', 'P103', 'P30']\n",
      "answerLabel\tPoaceae\n",
      "i:  {'id': 6, 'question': 'What is the top speed of a cheetah?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "top top ADJ amod\n",
      "speed speed NOUN nsubj\n",
      "of of ADP prep\n",
      "a a DET det\n",
      "cheetah cheetah NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q23907', 'Q28647560']\n",
      "found properties  ['P2052', 'P6783', 'P3695', 'P3694', 'P2350']\n",
      "answerLabel\t120\n",
      "i:  {'id': 7, 'question': 'Which color is a fox?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "Which which DET det\n",
      "color color NOUN nsubj\n",
      "is be AUX ROOT\n",
      "a a DET det\n",
      "fox fox NOUN attr\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q8331', 'Q1158210']\n",
      "found properties  ['P462', 'P1884', 'P465', 'P6338', 'P2827']\n",
      "answerLabel\tyellow\n",
      "answerLabel\tblack\n",
      "answerLabel\torange\n",
      "answerLabel\tbrown\n",
      "i:  {'id': 8, 'question': 'What does a plant consist of?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON pobj\n",
      "does do AUX aux\n",
      "a a DET det\n",
      "plant plant NOUN nsubj\n",
      "consist consist VERB ROOT\n",
      "of of ADP prep\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q756', 'Q346195']\n",
      "found properties  ['P527', 'P2635', 'P5238', 'P3989', 'P150']\n",
      "answerLabel\troot\n",
      "answerLabel\tplant stem\n",
      "answerLabel\tgerm layer\n",
      "answerLabel\tTrue leaf\n",
      "i:  {'id': 9, 'question': 'What is the life expectancy of a sloth?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "life life NOUN compound\n",
      "expectancy expectancy NOUN nsubj\n",
      "of of ADP prep\n",
      "a a DET det\n",
      "sloth sloth NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q2274076', 'Q7541428']\n",
      "found properties  ['P2250']\n",
      "answerLabel\t30\n",
      "answerLabel\t50\n",
      "i:  {'id': 10, 'question': 'Which products are made from a sheep?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "Which which DET det\n",
      "products product NOUN nsubjpass\n",
      "are be AUX auxpass\n",
      "made make VERB ROOT\n",
      "from from ADP prep\n",
      "a a DET det\n",
      "sheep sheep NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q7368', 'Q2702850']\n",
      "found properties  ['P1056', 'P7163', 'P176', 'P2079', 'P272', 'P1672', 'P2010', 'P2093', 'P176', 'P1056', 'P2283']\n",
      "answerLabel\tsheepskin\n",
      "answerLabel\tsheep wool\n",
      "answerLabel\tsheep milk\n",
      "i:  {'id': 11, 'question': 'How old can pandas become?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "How how SCONJ advmod\n",
      "old old ADJ acomp\n",
      "can can AUX aux\n",
      "pandas panda NOUN nsubj\n",
      "become become VERB ROOT\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q33602', 'Q1786478']\n",
      "found properties  ['P4214']\n",
      "answerLabel\t36.8\n",
      "i:  {'id': 12, 'question': 'How old can a European hedgehog get?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "language found: european\n",
      "european\n",
      "\n",
      "How how SCONJ advmod\n",
      "old old ADJ acomp\n",
      "can can AUX aux\n",
      "a a DET det\n",
      "European european ADJ amod\n",
      "hedgehog hedgehog NOUN nsubj\n",
      "get get VERB ROOT\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q6145', 'Q42954198']\n",
      "found properties  ['P4214']\n",
      "answerLabel\t11.7\n",
      "i:  {'id': 13, 'question': 'How old can the Great Basin Bristlecone Pine get?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "How how SCONJ advmod\n",
      "old old ADJ acomp\n",
      "can can AUX aux\n",
      "the the DET det\n",
      "Great Great PROPN compound\n",
      "Basin Basin PROPN compound\n",
      "Bristlecone Bristlecone PROPN compound\n",
      "Pine Pine PROPN nsubj\n",
      "get get VERB ROOT\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q1116374']\n",
      "found properties  ['P4214']\n",
      "answerLabel\t4854\n",
      "i:  {'id': 14, 'question': 'Where do koalas come from?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "Where where SCONJ pobj\n",
      "do do AUX aux\n",
      "koalas koala NOUN nsubj\n",
      "come come VERB ROOT\n",
      "from from ADP prep\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q36101', 'Q398951']\n",
      "found properties  ['P183', 'P156', 'P155', 'P495', 'P740', 'P1582']\n",
      "answerLabel\tAustralia\n",
      "i:  {'id': 15, 'question': 'What is the conservation status of the Atlantic salmon?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "conservation conservation NOUN compound\n",
      "status status NOUN nsubj\n",
      "of of ADP prep\n",
      "the the DET det\n",
      "Atlantic Atlantic PROPN compound\n",
      "salmon salmon NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q188879', 'Q54750570']\n",
      "found properties  ['P141', 'P5816']\n",
      "answerLabel\tLeast Concern\n",
      "i:  {'id': 16, 'question': 'What is the german name for chicken?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "language found: german\n",
      "german\n",
      "FILTER (lang(?answer) = \"de\")\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "german german ADJ amod\n",
      "name name NOUN nsubj\n",
      "for for ADP prep\n",
      "chicken chicken NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q780', 'Q864693']\n",
      "found properties  ['rdfs:label']\n",
      "answerLabel\tHuhn\n",
      "i:  {'id': 17, 'question': 'What is the dutch name for a bull?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "language found: dutch\n",
      "dutch\n",
      "FILTER (lang(?answer) = \"nl\")\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "dutch dutch ADJ amod\n",
      "name name NOUN nsubj\n",
      "for for ADP prep\n",
      "a a DET det\n",
      "bull bull NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q693690', 'Q24207659']\n",
      "found properties  ['rdfs:label']\n",
      "answerLabel\tstier\n",
      "i:  {'id': 18, 'question': 'Where is a kangaroo endemic to?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "Where where SCONJ advmod\n",
      "is be AUX ROOT\n",
      "a a DET det\n",
      "kangaroo kangaroo ADJ amod\n",
      "endemic endemic NOUN nsubj\n",
      "to to ADP prep\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q506680', 'Q419116']\n",
      "found properties  ['P183']\n",
      "i:  {'id': 19, 'question': 'What is the heart rate of a giraffe in bpm?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "heart heart NOUN compound\n",
      "rate rate NOUN nsubj\n",
      "of of ADP prep\n",
      "a a DET det\n",
      "giraffe giraffe PROPN pobj\n",
      "in in ADP prep\n",
      "bpm bpm NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q15083', 'Q862089', 'Q189214', 'Q743895']\n",
      "found properties  ['P3395']\n",
      "answerLabel\t150\n",
      "i:  {'id': 20, 'question': 'What is the French word for penguin?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "language found: french\n",
      "french\n",
      "FILTER (lang(?answer) = \"fr\")\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "French french ADJ amod\n",
      "word word NOUN nsubj\n",
      "for for ADP prep\n",
      "penguin penguin NOUN pobj\n",
      "? ? PUNCT punct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found entitites:  ['Q9147', 'Q3374730']\n",
      "found properties  ['P154', 'P5187', 'P676', 'P8814', 'P5191']\n",
      "answerLabel\tmanchot\n",
      "i:  {'id': 21, 'question': 'What is the average top speed of a cheetah?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "average average ADJ amod\n",
      "top top ADJ amod\n",
      "speed speed NOUN nsubj\n",
      "of of ADP prep\n",
      "a a DET det\n",
      "cheetah cheetah NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q23907', 'Q28647560']\n",
      "found properties  []\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "average average ADJ amod\n",
      "top top ADJ amod\n",
      "speed speed NOUN nsubj\n",
      "of of ADP prep\n",
      "a a DET det\n",
      "cheetah cheetah NOUN pobj\n",
      "? ? PUNCT punct\n",
      "cheetah\n",
      "speed\n",
      "What is the average top speed of a cheetah?\n",
      "answer\t120\n",
      "i:  {'id': 22, 'question': 'What color is a daffodil?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what DET det\n",
      "color color NOUN nsubj\n",
      "is be AUX ROOT\n",
      "a a DET det\n",
      "daffodil daffodil NOUN attr\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q29465', 'Q27983']\n",
      "found properties  ['P462', 'P1884', 'P465', 'P6338', 'P2827']\n",
      "answerLabel\tyellow\n",
      "i:  {'id': 23, 'question': 'What is the diel cycle of a polar bear?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "diel diel ADJ amod\n",
      "cycle cycle NOUN nsubj\n",
      "of of ADP prep\n",
      "a a DET det\n",
      "polar polar ADJ amod\n",
      "bear bear NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q33609', 'Q7209004']\n",
      "found properties  ['P9566']\n",
      "answerLabel\tdiurnal\n",
      "i:  {'id': 24, 'question': 'What is the life expectancy of a house cat?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "life life NOUN compound\n",
      "expectancy expectancy NOUN nsubj\n",
      "of of ADP prep\n",
      "a a DET det\n",
      "house house NOUN compound\n",
      "cat cat NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q146', 'Q20980826']\n",
      "found properties  ['P2250']\n",
      "answerLabel\t15\n",
      "i:  {'id': 25, 'question': 'What is the height of an elephant?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "height height NOUN nsubj\n",
      "of of ADP prep\n",
      "an an DET det\n",
      "elephant elephant NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q7378', 'Q2372824']\n",
      "found properties  ['P2044', 'P2048', 'P2793', 'P2923']\n",
      "answerLabel\t4\n",
      "i:  {'id': 26, 'question': 'What is the habitat of an ivy?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "habitat habitat NOUN nsubj\n",
      "of of ADP prep\n",
      "an an DET det\n",
      "ivy ivy NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q26354', 'Q26771']\n",
      "found properties  ['P2974']\n",
      "answerLabel\ttree\n",
      "answerLabel\twall\n",
      "answerLabel\tcliff\n",
      "answerLabel\tlowland\n",
      "i:  {'id': 27, 'question': 'What is the taxon rank of birch?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "taxon taxon ADJ amod\n",
      "rank rank NOUN nsubj\n",
      "of of ADP prep\n",
      "birch birch PROPN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q25243', 'Q14947702']\n",
      "found properties  ['P105']\n",
      "answerLabel\tgenus\n",
      "i:  {'id': 30, 'question': 'What is the main food source of an eagle?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "main main ADJ amod\n",
      "food food NOUN compound\n",
      "source source NOUN nsubj\n",
      "of of ADP prep\n",
      "an an DET det\n",
      "eagle eagle NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q2092297', 'Q358148']\n",
      "found properties  ['P1034']\n",
      "answerLabel\tlamb\n",
      "i:  {'id': 31, 'question': 'What is the parent taxon of a lion?', 'answer': 'white', 'correct': 1}\n",
      "id:  <class 'int'>\n",
      "question:  <class 'str'>\n",
      "What what PRON attr\n",
      "is be AUX ROOT\n",
      "the the DET det\n",
      "parent parent NOUN compound\n",
      "taxon taxon NOUN nsubj\n",
      "of of ADP prep\n",
      "a a DET det\n",
      "lion lion NOUN pobj\n",
      "? ? PUNCT punct\n",
      "found entitites:  ['Q140', 'Q338814']\n",
      "found properties  ['P171']\n",
      "answerLabel\tPanthera\n"
     ]
    }
   ],
   "source": [
    "# store and print the input as question string\n",
    "# question = input('Please ask your question\\n')\n",
    "# parse = nlp(question)\n",
    "\n",
    "#This function is meant to run the code with a csv file as input, run only if thats the case\n",
    "import json\n",
    "\n",
    "input = open('test.json')\n",
    "print(\"input: \", type(input))\n",
    "input_data = input.read()\n",
    "print(\"input_data: \", type(input_data))\n",
    "data = json.loads(input_data)\n",
    "output_data = []\n",
    "\n",
    "for i in data:\n",
    "    print(\"i: \", i)\n",
    "    id = i['id']\n",
    "    print(\"id: \", type(id))\n",
    "    question = i['question']\n",
    "    print(\"question: \", type(question))\n",
    "    parse = nlp(question)\n",
    "\n",
    "    dictionary ={\n",
    "    \"id\" : id, \n",
    "    \"question\" : question, \n",
    "    \"answer\" : getAnswer(question),\n",
    "    \"correct\" : ' '\n",
    "  }\n",
    "    \n",
    "    output_data.append(dictionary)\n",
    "  #json_object = json.dump(dictionary, indent = 4)\n",
    "\n",
    "with open('test_output.json', \"w\", encoding='utf-8') as output:\n",
    "    #output.write(json_object)\n",
    "    json.dump(output_data, output, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2Aj-jtBNnzr"
   },
   "source": [
    "## Questions that work:\n",
    "\n",
    "* What do cows eat?\n",
    "* What is the top speed of a cheetah?\n",
    "* What is the study of fish called?\n",
    "* What does a plant consist of?\n",
    "* What is the life expectancy of a sloth? -- there are two references, so two answers\n",
    "\n",
    "* Which products are made from a sheep?\n",
    "\n",
    "* How old can pandas become?\n",
    "* How old can a European hedgehog get?\n",
    "* How old can the Great Basin Bristlecone Pine get?\n",
    "\n",
    "* Where do koalas come from?\n",
    "\n",
    "* When did Mammoths go extinct? -- The date format is quite hard to read, needs polishing/units\n",
    "\n",
    "* What is the german name for chicken?\n",
    "\n",
    "* What is the dutch name for a bull?\n",
    "\n",
    "* Where is a kangaroo endemic to?\n",
    "\n",
    "* What is the heart rate of a giraffe in bpm?\n",
    "\n",
    "* What is the French word for penguin?\n",
    "\n",
    "Questions that do not work (yet):\n",
    "1. Who was the polar bear born in captivity at the Berlin Zoological Garden in 2006? - Answer: Knut\n",
    "The QUery should look something like this: \n",
    "'''SELECT ?nameLabel WHERE {\n",
    "  ?name wdt:P10241 wd:Q33609 .\n",
    "  ?name wdt:P19 wd:Q154828 .\n",
    "  ?name wdt:P569 ?birthdate .\n",
    "  FILTER (YEAR(?birthdate) <= 2007)\n",
    "  SERVICE wikibase:label {\n",
    "    bd:serviceParam wikibase:language \"en\" .\n",
    "  }\n",
    "}'''\n",
    "2. Where are kangaroos endemic to? - does not work because the lemma of kangaroos is kangaroos since it is interpreted as PROPN\n",
    "\n",
    "4. Which continent is the wombat endemic to? - does not work but works for Which continent is the common wombat endemic to?\n",
    "5. How long is the gestation period of the European Rabbit? - works locally\n",
    "\n",
    "* More questions :\n",
    "\n",
    "1. What is the average top speed of a cheetah?\n",
    "2. What is the highest observed lifespan in alpaca?\n",
    "3. What is the diel cycle of a polar bear?\n",
    "4. What are the parts of a tree? - does not give the correct answer because the property found is 'part' which is different from the 'parts' property\n",
    "5. What is the life expectancy of a house cat? - works but 'What is the life expectancy of a cat?' does not work\n",
    "6. What is the height of an elephant? and What is the average height of an elephant?\n",
    "7. What is the gestation period of an Asian elephant? - works but What is the average gestation period of an Asian elephant? does not work\n",
    "8. What is the habitat of an ivy?\n",
    "9. What is the taxon rank of birch?\n",
    "10. What is the main food source of an eagle?\n",
    "11. What is the parent taxon of a lion?\n",
    "12. What color is a daffodil?\n",
    "13. What is the conservation status of the Atlantic salmon?\n",
    "14. What is the average litter size of a jaguar?\n",
    "15. Which color is a fox?\n",
    "16. Which color is an elephant?\n",
    "17. Which animals do not have a spine? - spine is not property on wikidata page\n",
    "18. In which habitats do giraffes live? - works if it is habitat otherwise the dependency is wrong\n",
    "19. In which habitat do tulips grow best?\n",
    "20. In which country the International Plant Names Index is based? - works but In which country is the International Plant Names Index based? does not work because no subject is found \n",
    "21. In which country is the Old Tjikko tree located?\n",
    "22. Which colour can foxes be? and Which colours can foxes be? \n",
    "23. Which animals are in the big 5? - finds the correct entity, but not the correct property\n",
    "24. Which awards did Rosmarinus officinalis receive?\n",
    "25. Which awards did Salvia rosmarinus receive? - why I added verb as a nsubj\n",
    "26. Which awards did the rosemary receive? - why I added adj as a nsubj, without the is not working at all\n",
    "27. Which type of fruit do rubber trees produce? - finds first an incorrect property\n",
    "28. \n",
    "29. Which country is platypus endemic to?\n",
    "30. \n",
    "31. How long is the gestation period of a cow?\n",
    "32. Where is the Varanus komodoensis (komodo dragon) endemic to?\n",
    "33. Where is the cocoa plant endemic to?\n",
    "34. Which colours can the fruit of the apple tree have? - does not work but works for Which colours can the apple have?\n",
    "\n",
    "New addition:\n",
    "\n",
    "35. Are jaguars mammals?\n",
    "36. Are bananas berries?\n",
    "37. Is a lion a species of big cat?\n",
    "38. Are paeonias different from pions?\n",
    "39. Are elephants mammals?\n",
    "40. Is cannabis different from marihuana?\n",
    "41. Are bamboos edible plants? - does not work because the lemma of bamboos is bamboos since it is interpreted as ADJ but works for Are bamboo edible plants? and Is bamboo an edible plant?\n",
    "42. Are sheep herbivores?\n",
    "43. Do dolphins have a sense of self-awareness?\n",
    "44. Do tigers eat fruit?\n",
    "45. Is bamboo used inmaking clothing?\n",
    "46. Are roses edible?\n",
    "47. Can foxes have black fur?\n",
    "48. Are fungi plants?\n",
    "\n",
    "\n",
    "## Known bugs\n",
    "Resolved? Sometimes the system sends too many requests - I'm already in conversation about this with Joost. \n",
    "\n",
    "I changed how the system gives an answer, and now I think there is only one question for which the system sends too many requests: 'In which habitats do giraffes live?'.\n",
    "\n",
    "For some of the disguised questions, I need the classifier to find the corresponding synonyms\n",
    "\n",
    "/////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "FOR THE INPUT/OUTPUT:\n",
    "\n",
    "So it basically messes up with writing down the result in the json file when the result is url. There are two ways i can think of for fixing it:\n",
    "\n",
    "1. Either take only the label from the get label function as a return statement and record that. \n",
    "\n",
    "2. Or try and figure out how to record an url in a json file\n",
    "\n",
    "Also, if there is time, check out if the questions that don't work in the output file but work if you input them manually\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LTP_Final_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
